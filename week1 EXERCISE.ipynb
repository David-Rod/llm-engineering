{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "# constants\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL_LLAMA = 'llama3.2:1b'\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"I would like to know what are the most important aspects of learning Italian, and would like for you to construct \\\n",
    "    a curriculum to help me speak the language fluently in the next 6 months. Please design curriculum according the the latest \\\n",
    "    research on language mastery, allowing me to have a whole understanding of the language unlike the approach taken by modern \\\n",
    "    language learning applicaitons.\"\n",
    "\n",
    "user_prompt = \"Please give a detailed explanation to the following question: \" + question\n",
    "\n",
    "system_prompt = \"You are an assistant that the questions presented by a user and generates thoughtful analysis \\\n",
    "and creates concise and clear summaries that are organized by category of relevant information. Respond in markdown.\\\n",
    "Please include descriptive examples and be sure to frame the response in the context of the quetion provided.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "    )\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "dir(stream)\n",
    "for chunk in stream:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "payload = {\n",
    "        \"model\": MODEL_LLAMA,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": True\n",
    "    }\n",
    "ollama_response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb703b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert byte string repsonse to single markdown string response\n",
    "string_response = ollama_response.content.decode('utf-8')\n",
    "json_objects = []\n",
    "\n",
    "for line in string_response.strip().split('\\n'):\n",
    "    if line.strip():\n",
    "        json_object = json.loads(line)\n",
    "        json_objects.append(json_object)\n",
    "\n",
    "combined_message_str = \"\"\n",
    "for json_obj in json_objects:\n",
    "    combined_message_str+=json_obj['message']['content']\n",
    "\n",
    "display(Markdown(combined_message_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec104c-1608-49fc-b2b0-295a7f94b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "ollama_response_2 = ollama.chat(model=MODEL_LLAMA, messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b392d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(ollama_response_2.message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
