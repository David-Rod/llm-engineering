{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8df402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import imaplib\n",
    "import yaml\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "import email\n",
    "\n",
    "from email.parser import Parser\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "parser = Parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98df32e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: sk-proj-C1...\n"
     ]
    }
   ],
   "source": [
    "db_name = \"email_vector_db\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "load_dotenv('../.env/.env-config', override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "print(\"OpenAI API Key:\", os.environ['OPENAI_API_KEY'][:10] + '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38395843",
   "metadata": {},
   "source": [
    "# Setup and Imports\n",
    "Run this cell first to make all imports available for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "455932a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credentials(filename, config_dir='.env'):\n",
    "    current_dir = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "    filepath = current_dir.parent / config_dir / filename\n",
    "\n",
    "    try:\n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"Credentials file not found at: {filepath}\")\n",
    "\n",
    "        with open(filepath, 'r') as file:\n",
    "            credentials = yaml.safe_load(file)\n",
    "\n",
    "            if not isinstance(credentials, dict):\n",
    "                raise ValueError(\"Credentials file must contain a YAML dictionary\")\n",
    "\n",
    "            if 'user' not in credentials or 'password' not in credentials:\n",
    "                raise KeyError(\"Credentials file must contain 'user' and 'password' fields\")\n",
    "\n",
    "            return credentials['user'], credentials['password']\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load credentials from {filepath}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a35013e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email_from_string(email_string):\n",
    "    email_message = parser.parsestr(email_string)\n",
    "    return email_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c9d7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_gmail_imap(*credentials) -> imaplib.IMAP4_SSL:\n",
    "    email, app_token = credentials\n",
    "    mail = imaplib.IMAP4_SSL('imap.gmail.com', 993)\n",
    "    mail.login(email, app_token)\n",
    "    return mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71d53603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_message_to_file(message_numbers, filename='knowledge-base/email-file.txt'):\n",
    "\n",
    "    file_path = Path(filename)\n",
    "    if file_path.exists():\n",
    "        file_path.unlink()\n",
    "        print(f\"Deleted {file_path}\")\n",
    "    else:\n",
    "        print(f\"File {file_path} does not exist\")\n",
    "\n",
    "    for num in message_numbers[0].split():\n",
    "        typ, msg_data = mail.fetch(num, '(RFC822)')\n",
    "        emails = parse_email_from_string(msg_data[0][1].decode(\"utf-8\"))\n",
    "        payload = emails.get_payload()[0].get_payload()\n",
    "\n",
    "        if not isinstance(payload, list):\n",
    "            content = payload\n",
    "        else:\n",
    "            content = ''\n",
    "\n",
    "        cleantext = BeautifulSoup(content, \"html.parser\").text\n",
    "        with open(filename, 'a') as f:\n",
    "            f.write(f\"\\n--- Email {num.decode()} ---\\n\")\n",
    "            f.write(str(cleantext))\n",
    "            f.write(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4793f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted knowledge-base/email-file.txt\n"
     ]
    }
   ],
   "source": [
    "credentials = load_credentials('credentials.yaml')\n",
    "mail = connect_to_gmail_imap(*credentials)\n",
    "mail.select('INBOX')\n",
    "mail.select('\"[Gmail]/All Mail\"')  # This gets ALL emails in your account\n",
    "status, message_numbers = mail.search(None, 'FROM \"amazon.com\"')\n",
    "write_message_to_file(message_numbers)\n",
    "# status, folders = mail.list()\n",
    "# print(\"Available folders:\")\n",
    "# for folder in folders:\n",
    "#     folder_name = folder.decode('utf-8')\n",
    "#     print(f\"  {folder_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19d344e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1040, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 862, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1040, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 774, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 810, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1040, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1040, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 990, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 990, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 990, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1253, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1006, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 990, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 1040, which is longer than the specified 750\n",
      "WARNING:langchain_text_splitters.base:Created a chunk of size 990, which is longer than the specified 750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 87\n"
     ]
    }
   ],
   "source": [
    "text_files = glob.glob(\"knowledge-base/*\")\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "documents = []\n",
    "\n",
    "for file_path in text_files:\n",
    "    loader = TextLoader(file_path, **text_loader_kwargs)\n",
    "    doc = loader.load()\n",
    "    documents.extend(doc)\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=750, chunk_overlap=100, separator=\"\\n\\n\", strip_whitespace=True )\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Total number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d20a9bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 87 documents\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2e4bd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 87 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "679f1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# Alternative - if you'd like to use Ollama locally, uncomment this line instead\n",
    "# llm = ChatOpenAI(temperature=0.7, model_name='llama3.2', base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48ec3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c02d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cample Questions:\n",
    "# Please tell me if my Amazon emails contain information about a portable monitor\n",
    "# Please tell me if my Amazon emails contain information about a Newporter Classic guitar\n",
    "# Can you provide order details from that order based on my Amazon emails?\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
