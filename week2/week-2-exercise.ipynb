{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add agent that translates responses to a different language, using different frontier model\n",
    "# Add agent that can listen for audio and convert it to text\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import anthropic\n",
    "from openai import OpenAI\n",
    "import whisper\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58314478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-pro\n",
      "Anthropic API key exists and begins with sk-ant\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:6]}\")\n",
    "\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API key exists and begins with {anthropic_api_key[:6]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "CLAUDE_MODEL = \"claude-3-5-sonnet-20241022\"\n",
    "OLLAMA_MODEL = \"llama3.2:1b\"\n",
    "AUDIO_MODEL = \"tts-1\"\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "725ed784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translation_message = \"You are a helpful assistant. Your primary role is to translate the user's input from English to Italian, or from Italan to English. \"\n",
    "translation_message += \"You will receive a message from the user, and you should respond to user input translated in the appropriate language. \"\n",
    "translation_message += \"If the user prompt input is in Italian, response in English, or reply with 'I don't understand (non capisco). \"\n",
    "translation_message += \"If the input is in English, respond in Italian, or reply with 'Non capisco (I don't understand)'. Examples: \"\n",
    "# Multishot prompting\n",
    "translation_message += \"If the user says 'Hello, how are you?', respond with 'Ciao, come stai?' or a with a standard reply to the question or statement. \"\n",
    "translation_message += \"If the user says 'Ciao, come stai?', respond with 'Hello, how are you?' or a with a standard reply to the question or statement. \"\n",
    "translation_message += \"If the user says 'Non capisco', respond with 'I don't understand'. \"\n",
    "translation_message += \"If the user says 'I don't understand', respond with 'Non capisco'. \"\n",
    "translation_message += \"If the user says please translate 'Hello, how are you?' to Italian, respond with 'Ciao, come stai?' or a with a standard reply to the question or statement. \"\n",
    "translation_message += \"If the user says please translate 'Ciao, come stai?' to English, respond with 'Hello, how are you?' or a with a standard reply to the question or statement. \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d900dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stream_claude(prompt):\n",
    "    result = claude.messages.stream(\n",
    "    model=CLAUDE_MODEL,\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=translation_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    )\n",
    "\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "               yield text\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": translation_message},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        text = chunk.choices[0].delta.content or ''\n",
    "        if text:\n",
    "            yield text\n",
    "\n",
    "def stream_llama(prompt):\n",
    "    ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=OLLAMA_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": translation_message},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in stream:\n",
    "        text = chunk.choices[0].delta.content or ''\n",
    "        if text:\n",
    "            yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d88c943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    elif model == \"Llama\":\n",
    "        result = stream_llama(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd5c9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "openai.audio.speech\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=AUDIO_MODEL,\n",
    "      voice=\"shimmer\",\n",
    "      input=message\n",
    "    )\n",
    "\n",
    "    audio_stream = BytesIO(response.content)\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f86ce537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text():\n",
    "    model = whisper.load_model(\"small\")\n",
    "\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(\"audio.mp3\")\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions()\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    # print the recognized text\n",
    "    print(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba392f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [{\"type\": \"function\", \"function\": translate_text}]\n",
    "\n",
    "def handle_tool_call(prompt):\n",
    "    if \"translate\" in prompt.lower():\n",
    "        response = translate_text(prompt)\n",
    "    else:\n",
    "        response = \"I don't understand the tool call.\"\n",
    "\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37b42a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/tmp/tmpcdsyqo9d.wav':   0KB sq=    0B \n",
      "  Duration: 00:00:01.54, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   1.39 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/tmp/tmpvzo7egv2.wav':   0KB sq=    0B \n",
      "  Duration: 00:00:02.54, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   2.43 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/tmp/tmpvpslw4uh.wav':   0KB sq=    0B \n",
      "  Duration: 00:00:03.53, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   3.46 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "        model_selector = gr.Dropdown([\"Claude\", \"GPT\", \"Llama\"], label=\"Select model\", value=\"Claude\")\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=207, type=\"messages\")\n",
    "        translation_output = gr.Textbox(label=\"Translation Output\", placeholder=\"Translated text will appear here\", lines=7)\n",
    "\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def do_entry(message, history, model):\n",
    "        if model == \"Claude\":\n",
    "            translation = \"\".join(stream_claude(message))\n",
    "        elif model == \"GPT\":\n",
    "            translation = \"\".join(stream_gpt(message))\n",
    "        elif model == \"Llama\":\n",
    "            translation = \"\".join(stream_llama(message))\n",
    "        else:\n",
    "            translation = \"Unknown model\"\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        talker(translation)\n",
    "\n",
    "        return \"\", history, translation\n",
    "\n",
    "\n",
    "    entry.submit(\n",
    "        do_entry,\n",
    "        inputs=[entry, chatbot, model_selector],\n",
    "        outputs=[entry, chatbot, translation_output]\n",
    "    )\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
